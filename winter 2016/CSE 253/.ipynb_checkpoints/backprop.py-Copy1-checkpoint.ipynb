{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "from __future__          import division\n",
    "from scipy.stats         import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import array\n",
    "import math\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(images_file, labels_file): \n",
    "    f1 = open(labels_file, 'rb')\n",
    "    magic_number, size = struct.unpack(\">II\", f1.read(8))\n",
    "    labels = array.array(\"b\", f1.read())\n",
    "    f1.close()\n",
    "    \n",
    "    f2 = open(images_file, 'rb')\n",
    "    magic_number, size, rows, cols = struct.unpack(\">IIII\", f2.read(16))\n",
    "    raw_images = array.array(\"B\", f2.read())\n",
    "    f2.close()\n",
    "\n",
    "    N = len(labels)\n",
    "    images = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    for i in range(N):\n",
    "        images[i] = np.array(raw_images[ i*rows*cols : (i+1)*rows*cols ])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Read Training data.\n",
    "TRAIN_IMAGES  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-images.idx3-ubyte\"\n",
    "TRAIN_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-labels.idx1-ubyte\"\n",
    "images_train, labels_train = read_mnist(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "#images_train, labels_train = images_train[:20000], labels_train[:20000]\n",
    "\n",
    "# Read Test data.\n",
    "TEST_IMAGES = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-images.idx3-ubyte\"\n",
    "TEST_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-labels.idx1-ubyte\"\n",
    "images_test, labels_test = read_mnist(TEST_IMAGES, TEST_LABELS)\n",
    "#images_test, labels_test = images_test[:2000], labels_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid(ele) for ele in x])\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid_derivate(ele) for ele in x])\n",
    "    else:\n",
    "        a = sigmoid(x)\n",
    "        return a * (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = zscore(images_train, axis=1)\n",
    "Y = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_train]\n",
    "X_test = zscore(images_test, axis=1)\n",
    "Y_test = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, outputs, learning_rate, layers, \n",
    "                 activation_fn, activation_derivative_fn, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        TODO: Add doc.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = layers\n",
    "        self.activation_fn = activation_fn\n",
    "        self.activation_derivative_fn = activation_derivative_fn\n",
    "    \n",
    "    def get_random_weights(self):\n",
    "        weights = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            weights.append(np.random.random((self.layers[i]+1, self.layers[i+1])))\n",
    "        return weights\n",
    "    \n",
    "    def get_gradients(self, X, Y, weights):\n",
    "        # Forward propogation.\n",
    "        a,z = self.get_network_output(X, weights)\n",
    "        # Backward error propogation.\n",
    "        deltas = []\n",
    "        #print a[-1], Y, z[-1]\n",
    "        deltas.append((a[-1] - Y)*self.activation_derivative_fn(z[-1]))\n",
    "        for l in reversed(range(1, len(self.layers)-1)):\n",
    "            deltas.append(np.dot(weights[l], deltas[-1])*self.activation_derivative_fn(z[l]))\n",
    "        deltas.reverse()\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(weights)):\n",
    "            if i != (len(weights)-1):\n",
    "                deltas[i] = deltas[i][1:]\n",
    "            gradients.append(np.dot(np.atleast_2d(a[i]).transpose(), np.atleast_2d(deltas[i])))\n",
    "        return gradients\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the data using multilayered.\n",
    "        \"\"\"\n",
    "        weights = self.get_random_weights()\n",
    "        #self.cross_entropy(weights)\n",
    "        \n",
    "        # 5 iterations.\n",
    "        for i in range(10):\n",
    "            for i in range(len(self.inputs)):\n",
    "                X = np.insert(self.inputs[i], 0, 1)\n",
    "                Y = self.outputs[i]\n",
    "                gradients = self.get_gradients(X,Y,weights)\n",
    "                # Use gradient descent algorithm to update\n",
    "                # accordingly due to error derivates.\n",
    "                for i in range(len(weights)):\n",
    "                    weights[i] = weights[i] - self.learning_rate * gradients[i]\n",
    "\n",
    "            #self.cross_entropy(weights)\n",
    "            self.testXOR(self.inputs, self.outputs, weights)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return weights\n",
    "        \n",
    "    def get_network_output(self, X, weights):\n",
    "        \"\"\"\n",
    "        Calculates the output at each layer of the network.\n",
    "        \"\"\"\n",
    "        #print \"----\"\n",
    "        #print weights[0].shape, weights[1].shape\n",
    "        a = [X]\n",
    "        z = [X]\n",
    "        for l in range(len(self.layers)-1):\n",
    "            zl = np.dot(weights[l].transpose(), z[l])\n",
    "            if l == (len(self.layers)-2):\n",
    "                if self.layers[-1] == 1:\n",
    "                    a.append(self.activation_fn(zl))\n",
    "                    z.append(zl)\n",
    "                else:\n",
    "                    # Softmax output function.\n",
    "                    output = np.vectorize(math.exp)(zl)\n",
    "                    output = output / output.sum()\n",
    "                    a.append(output)\n",
    "                    z.append(zl)\n",
    "                    #print zl.shape, zl\n",
    "            else:\n",
    "                z.append(np.insert(zl,0,1))\n",
    "                al = self.activation_fn(zl)\n",
    "                #print zl.shape, zl\n",
    "                # Add bias.\n",
    "                a.append(np.insert(al,0,1))\n",
    "        return a,z\n",
    "    \n",
    "    def cross_entropy(self, weights):\n",
    "        entropy = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            a,z = self.get_network_output(np.insert(self.inputs[i], 0, 1), weights)\n",
    "            y = a[-1]\n",
    "            t = self.outputs[i]\n",
    "            entropy += np.dot(t, np.vectorize(math.log)(y))\n",
    "        return -entropy\n",
    "    \n",
    "    def test(self, test_input, test_output):\n",
    "        weights = self.weights\n",
    "        error = 0\n",
    "        for i in range(len(test_input)):\n",
    "            X = np.insert(test_input[i], 0, 1)\n",
    "            T = test_output[i]\n",
    "            a,z = self.get_network_output(X, weights)\n",
    "            predicted_digit = a[-1].argmax()\n",
    "            if T[predicted_digit] != 1:\n",
    "                error += 1\n",
    "        print \"Error is %.2f\" %(error*100/len(test_input))\n",
    "    \n",
    "    def testXOR(self, test_input, test_output, weights):\n",
    "        error = 0\n",
    "        for i in range(len(test_input)):\n",
    "            X = np.insert(test_input[i], 0, 1)\n",
    "            T = test_output[i]\n",
    "            a,z = self.get_network_output(X, weights)\n",
    "            print a[-1][0], T\n",
    "        print \"--------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772429130922 0\n",
      "0.924403900942 1\n",
      "0.915871268494 1\n",
      "0.975136910515 0\n",
      "--------\n",
      "0.781217216098 0\n",
      "0.929625623183 1\n",
      "0.9214850749 1\n",
      "0.977486661923 0\n",
      "--------\n",
      "0.789698029775 0\n",
      "0.934456638314 1\n",
      "0.926695416347 1\n",
      "0.979590795188 0\n",
      "--------\n",
      "0.797867155336 0\n",
      "0.938921788852 1\n",
      "0.931526088408 1\n",
      "0.981474927507 0\n",
      "--------\n",
      "0.805722690758 0\n",
      "0.943045572727 1\n",
      "0.936000852474 1\n",
      "0.983162348886 0\n",
      "--------\n",
      "0.813265014963 0\n",
      "0.946851860477 1\n",
      "0.940143116046 1\n",
      "0.984674131623 0\n",
      "--------\n",
      "0.820496539457 0\n",
      "0.950363676623 1\n",
      "0.94397567688 1\n",
      "0.98602926283 0\n",
      "--------\n",
      "0.827421453558 0\n",
      "0.95360303794 1\n",
      "0.947520525092 1\n",
      "0.987244790536 0\n",
      "--------\n",
      "0.834045470666 0\n",
      "0.956590841121 1\n",
      "0.950798696708 1\n",
      "0.988335976013 0\n",
      "--------\n",
      "0.840375581857 0\n",
      "0.959346792414 1\n",
      "0.953830171941 1\n",
      "0.989316446783 0\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([np.array([0,0]), \n",
    "              np.array([0,1]), \n",
    "              np.array([1,0]), \n",
    "              np.array([1,1])\n",
    "             ])\n",
    "Y1 = np.array([0,1,1,0])\n",
    "network = MultiLayerNeuralNetwork(inputs=X1,\n",
    "                                  outputs=Y1,\n",
    "                                  learning_rate=0.2,\n",
    "                                  layers=[2,2,1],\n",
    "                                  activation_fn=sigmoid,\n",
    "                                  activation_derivative_fn=sigmoid_derivate\n",
    "                                 )\n",
    "weights = network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,z = network.get_network_output(np.insert(X1[0], 0 , 1) , network.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 0, 0]), array([ 1.        ,  0.99621497,  0.99636434]), array([ 1.])]\n"
     ]
    }
   ],
   "source": [
    "math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.57290832,  5.61332277],\n",
       "       [ 1.95687501,  1.89989565],\n",
       "       [ 1.98279642,  1.78634371]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14302260418\n",
      "2.15789843117\n"
     ]
    }
   ],
   "source": [
    "weights = network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 91.30\n"
     ]
    }
   ],
   "source": [
    "network.test(X_test[:1000], Y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(0.920000742938)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,) and (1,) not aligned: 2 (dim 0) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-da988d917687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,) and (1,) not aligned: 2 (dim 0) != 1 (dim 0)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-6-da988d917687>\u001b[0m(1)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m----> 1 \u001b[1;33m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "np.dot(np.array([1,2]).transpose(), np.array([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
