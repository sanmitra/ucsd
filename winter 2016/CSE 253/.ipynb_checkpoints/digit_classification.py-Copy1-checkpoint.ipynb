{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "from __future__          import division\n",
    "from scipy.stats         import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import array\n",
    "import math\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(images_file, labels_file): \n",
    "    f1 = open(labels_file, 'rb')\n",
    "    magic_number, size = struct.unpack(\">II\", f1.read(8))\n",
    "    labels = array.array(\"b\", f1.read())\n",
    "    f1.close()\n",
    "    \n",
    "    f2 = open(images_file, 'rb')\n",
    "    magic_number, size, rows, cols = struct.unpack(\">IIII\", f2.read(16))\n",
    "    raw_images = array.array(\"B\", f2.read())\n",
    "    f2.close()\n",
    "\n",
    "    N = len(labels)\n",
    "    images = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    for i in range(N):\n",
    "        images[i] = np.array(raw_images[ i*rows*cols : (i+1)*rows*cols ])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Read Training data.\n",
    "TRAIN_IMAGES  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-images.idx3-ubyte\"\n",
    "TRAIN_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-labels.idx1-ubyte\"\n",
    "images_train, labels_train = read_mnist(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "#images_train, labels_train = images_train[:20000], labels_train[:20000]\n",
    "\n",
    "# Read Test data.\n",
    "TEST_IMAGES = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-images.idx3-ubyte\"\n",
    "TEST_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-labels.idx1-ubyte\"\n",
    "images_test, labels_test = read_mnist(TEST_IMAGES, TEST_LABELS)\n",
    "#images_test, labels_test = images_test[:2000], labels_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid(ele) for ele in x])\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = zscore(images_train, axis=1)\n",
    "Y = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_train]\n",
    "X_test = zscore(images_test, axis=1)\n",
    "Y_test = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, outputs, learning_rate, layers, \n",
    "                 activation_fn, activation_derivative_fn, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        TODO: Add doc.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = layers\n",
    "        self.activation_fn = activation_fn\n",
    "        self.activation_derivative_fn = activation_derivative_fn\n",
    "    \n",
    "    def get_random_weights(self):\n",
    "        weights = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            weights.append(np.random.random((self.layers[i]+1, \n",
    "                                             self.layers[i+1])))\n",
    "        return weights\n",
    "    \n",
    "    def get_gradients(self, X, Y, weights):\n",
    "        # Forward propogation.\n",
    "        a,z = self.get_network_output(X, weights)\n",
    "        \n",
    "        # Backward error propogation.\n",
    "        deltas = []\n",
    "        deltas.append((a[-1] - Y))\n",
    "        for l in reversed(range(1, len(self.layers)-1)):\n",
    "            deltas.append(np.dot(weights[l], deltas[-1])*self.activation_derivative_fn(z[l]))\n",
    "        deltas.reverse()\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(weights)):\n",
    "            if i != (len(weights)-1):\n",
    "                deltas[i] = deltas[i][1:]\n",
    "            gradients.append(np.dot(np.atleast_2d(a[i]).transpose(), \n",
    "                                    np.atleast_2d(deltas[i])))\n",
    "        return gradients\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the data using multilayered.\n",
    "        \"\"\"\n",
    "        weights = self.get_random_weights()\n",
    "        \n",
    "        # 5 iterations.\n",
    "        for i in range(100):\n",
    "            for i in range(len(self.inputs)):\n",
    "                X = np.insert(self.inputs[i], 0, 1)\n",
    "                Y = self.outputs[i]\n",
    "                gradients = self.get_gradients(X,Y,weights)\n",
    "                # Use gradient descent algorithm to update\n",
    "                # accordingly due to error derivates.\n",
    "                for i in range(len(weights)):\n",
    "                    weights[i] = weights[i] - self.learning_rate * gradients[i]\n",
    "\n",
    "            print self.test(self.inputs, self.outputs, weights)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return weights\n",
    "        \n",
    "    def get_network_output(self, X, weights):\n",
    "        \"\"\"\n",
    "        Calculates the output at each layer of the network.\n",
    "        \"\"\"\n",
    "        a = [X]\n",
    "        z = [X]\n",
    "        for l in range(len(self.layers)-1):\n",
    "            zl = np.dot(weights[l].transpose(), z[l])\n",
    "            if l == (len(self.layers)-2):\n",
    "                output = np.vectorize(math.exp)(zl)\n",
    "                output = output / output.sum()\n",
    "                a.append(output)\n",
    "                z.append(zl)\n",
    "            else:\n",
    "                z.append(np.insert(zl,0,1))\n",
    "                a.append(np.insert(self.activation_fn(zl),0,1))\n",
    "        return a,z\n",
    "    \n",
    "    def cross_entropy(self, weights):\n",
    "        entropy = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            a,z = self.get_network_output(np.insert(self.inputs[i], 0, 1), \n",
    "                                          weights)\n",
    "            y = a[-1]\n",
    "            t = self.outputs[i]\n",
    "            entropy += np.dot(t, np.vectorize(math.log)(y))\n",
    "        return -entropy\n",
    "    \n",
    "    def test(self, test_input, test_output, weights):\n",
    "        error = 0\n",
    "        for i in range(len(test_input)):\n",
    "            X = np.insert(test_input[i], 0, 1)\n",
    "            T = test_output[i]\n",
    "            a,z = self.get_network_output(X, weights)\n",
    "            predicted_digit = a[-1].argmax()\n",
    "            if T[predicted_digit] != 1:\n",
    "                error += 1\n",
    "        print \"Error is %.2f\" %(error*100/len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = MultiLayerNeuralNetwork(inputs=X[:20000],\n",
    "                                  outputs=Y[:20000],\n",
    "                                  learning_rate=0.001,\n",
    "                                  layers=[784,100,10],\n",
    "                                  activation_fn=sigmoid,\n",
    "                                  activation_derivative_fn=sigmoid_derivate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 24.98\n",
      "None\n",
      "Error is 19.89\n",
      "None\n",
      "Error is 18.01\n",
      "None\n",
      "Error is 16.89\n",
      "None\n",
      "Error is 16.13\n",
      "None\n",
      "Error is 15.49\n",
      "None\n",
      "Error is 14.93\n",
      "None\n",
      "Error is 14.59\n",
      "None\n",
      "Error is 14.29\n",
      "None\n",
      "Error is 13.99\n",
      "None\n",
      "Error is 13.79\n",
      "None\n",
      "Error is 13.57\n",
      "None\n",
      "Error is 13.29\n",
      "None\n",
      "Error is 13.19\n",
      "None\n",
      "Error is 13.08\n",
      "None\n",
      "Error is 12.86\n",
      "None\n",
      "Error is 12.69\n",
      "None\n",
      "Error is 12.54\n",
      "None\n",
      "Error is 12.36\n",
      "None\n",
      "Error is 12.27\n",
      "None\n",
      "Error is 12.14\n",
      "None\n",
      "Error is 12.07\n",
      "None\n",
      "Error is 11.99\n",
      "None\n",
      "Error is 11.90\n",
      "None\n",
      "Error is 11.82\n",
      "None\n",
      "Error is 11.78\n",
      "None\n",
      "Error is 11.71\n",
      "None\n",
      "Error is 11.59\n",
      "None\n",
      "Error is 11.47\n",
      "None\n",
      "Error is 11.42\n",
      "None\n",
      "Error is 11.30\n",
      "None\n",
      "Error is 11.21\n",
      "None\n",
      "Error is 11.08\n",
      "None\n",
      "Error is 10.95\n",
      "None\n",
      "Error is 10.87\n",
      "None\n",
      "Error is 10.81\n",
      "None\n",
      "Error is 10.73\n",
      "None\n",
      "Error is 10.72\n",
      "None\n",
      "Error is 10.74\n",
      "None\n",
      "Error is 10.77\n",
      "None\n",
      "Error is 10.80\n",
      "None\n",
      "Error is 10.72\n",
      "None\n",
      "Error is 10.62\n",
      "None\n",
      "Error is 10.58\n",
      "None\n",
      "Error is 10.56\n",
      "None\n",
      "Error is 10.55\n",
      "None\n",
      "Error is 10.55\n",
      "None\n",
      "Error is 10.46\n",
      "None\n",
      "Error is 10.48\n",
      "None\n",
      "Error is 10.53\n",
      "None\n",
      "Error is 10.61\n",
      "None\n",
      "Error is 10.54\n",
      "None\n",
      "Error is 10.37\n",
      "None\n",
      "Error is 10.26\n",
      "None\n",
      "Error is 10.16\n",
      "None\n",
      "Error is 10.29\n",
      "None\n",
      "Error is 10.18\n",
      "None\n",
      "Error is 10.12\n",
      "None\n",
      "Error is 9.88\n",
      "None\n",
      "Error is 10.06\n",
      "None\n",
      "Error is 10.00\n",
      "None\n",
      "Error is 9.98\n",
      "None\n",
      "Error is 10.06\n",
      "None\n",
      "Error is 9.91\n",
      "None\n",
      "Error is 9.93\n",
      "None\n",
      "Error is 9.83\n",
      "None\n",
      "Error is 9.82\n",
      "None\n",
      "Error is 9.69\n",
      "None\n",
      "Error is 9.77\n",
      "None\n",
      "Error is 9.88\n",
      "None\n",
      "Error is 9.68\n",
      "None\n",
      "Error is 9.69\n",
      "None\n",
      "Error is 9.60\n",
      "None\n",
      "Error is 9.56\n",
      "None\n",
      "Error is 9.55\n",
      "None\n",
      "Error is 9.69\n",
      "None\n",
      "Error is 9.51\n",
      "None\n",
      "Error is 9.85\n",
      "None\n",
      "Error is 9.26\n",
      "None\n",
      "Error is 9.22\n",
      "None\n",
      "Error is 9.39\n",
      "None\n",
      "Error is 9.16\n",
      "None\n",
      "Error is 9.62\n",
      "None\n",
      "Error is 9.14\n",
      "None\n",
      "Error is 9.63\n",
      "None\n",
      "Error is 9.76\n",
      "None\n",
      "Error is 9.93\n",
      "None\n",
      "Error is 9.35\n",
      "None\n",
      "Error is 9.52\n",
      "None\n",
      "Error is 9.67\n",
      "None\n",
      "Error is 8.96\n",
      "None\n",
      "Error is 9.97\n",
      "None\n",
      "Error is 9.54\n",
      "None\n",
      "Error is 9.35\n",
      "None\n",
      "Error is 9.46\n",
      "None\n",
      "Error is 9.41\n",
      "None\n",
      "Error is 9.47\n",
      "None\n",
      "Error is 9.81\n",
      "None\n",
      "Error is 9.50\n",
      "None\n",
      "Error is 9.54\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "weights = network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 12.21\n"
     ]
    }
   ],
   "source": [
    "network.test(X_test, Y_test, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
