{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "from __future__          import division\n",
    "from scipy.stats         import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import array\n",
    "import math\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(images_file, labels_file): \n",
    "    f1 = open(labels_file, 'rb')\n",
    "    magic_number, size = struct.unpack(\">II\", f1.read(8))\n",
    "    labels = array.array(\"b\", f1.read())\n",
    "    f1.close()\n",
    "    \n",
    "    f2 = open(images_file, 'rb')\n",
    "    magic_number, size, rows, cols = struct.unpack(\">IIII\", f2.read(16))\n",
    "    raw_images = array.array(\"B\", f2.read())\n",
    "    f2.close()\n",
    "\n",
    "    N = len(labels)\n",
    "    images = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    for i in range(N):\n",
    "        images[i] = np.array(raw_images[ i*rows*cols : (i+1)*rows*cols ])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Read Training data.\n",
    "TRAIN_IMAGES  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-images.idx3-ubyte\"\n",
    "TRAIN_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-labels.idx1-ubyte\"\n",
    "images_train, labels_train = read_mnist(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "#images_train, labels_train = images_train[:20000], labels_train[:20000]\n",
    "\n",
    "# Read Test data.\n",
    "TEST_IMAGES = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-images.idx3-ubyte\"\n",
    "TEST_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-labels.idx1-ubyte\"\n",
    "images_test, labels_test = read_mnist(TEST_IMAGES, TEST_LABELS)\n",
    "#images_test, labels_test = images_test[:2000], labels_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid(ele) for ele in x])\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid_derivate(ele) for ele in x])\n",
    "    else:\n",
    "        a = sigmoid(x)\n",
    "        return a * (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = zscore(images_train, axis=1)\n",
    "Y = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_train]\n",
    "X_test = zscore(images_test, axis=1)\n",
    "Y_test = [np.array([1 if i == label else 0 for i in range(10)]) for label in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, outputs, learning_rate, layers, \n",
    "                 activation_fn, activation_derivative_fn, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        TODO: Add doc.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.layers = layers\n",
    "        self.activation_fn = activation_fn\n",
    "        self.activation_derivative_fn = activation_derivative_fn\n",
    "    \n",
    "    def get_random_weights(self):\n",
    "        weights = []\n",
    "        for i in range(len(self.layers)-1):\n",
    "            weights.append(np.random.random((self.layers[i]+1, \n",
    "                                             self.layers[i+1])))\n",
    "        return weights\n",
    "    \n",
    "    def get_gradients(self, X, Y, weights):\n",
    "        # Forward propogation.\n",
    "        a,z = self.get_network_output(X, weights)\n",
    "        \n",
    "        # Backward error propogation.\n",
    "        deltas = []\n",
    "        deltas.append((a[-1] - Y))\n",
    "        for l in reversed(range(1, len(self.layers)-1)):\n",
    "            deltas.append(np.dot(weights[l], deltas[-1])*self.activation_derivative_fn(z[l]))\n",
    "        deltas.reverse()\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(weights)):\n",
    "            if i != (len(weights)-1):\n",
    "                deltas[i] = deltas[i][1:]\n",
    "            gradients.append(np.dot(np.atleast_2d(a[i]).transpose(), \n",
    "                                    np.atleast_2d(deltas[i])))\n",
    "        return gradients\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the data using multilayered.\n",
    "        \"\"\"\n",
    "        weights = self.get_random_weights()\n",
    "        \n",
    "        # 5 iterations.\n",
    "        for i in range(100):\n",
    "            for i in range(len(self.inputs)):\n",
    "                X = np.insert(self.inputs[i], 0, 1)\n",
    "                Y = self.outputs[i]\n",
    "                gradients = self.get_gradients(X,Y,weights)\n",
    "                # Use gradient descent algorithm to update\n",
    "                # accordingly due to error derivates.\n",
    "                for i in range(len(weights)):\n",
    "                    weights[i] = weights[i] - self.learning_rate * gradients[i]\n",
    "\n",
    "            print self.test(self.inputs, self.outputs, weights)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return weights\n",
    "        \n",
    "    def get_network_output(self, X, weights):\n",
    "        \"\"\"\n",
    "        Calculates the output at each layer of the network.\n",
    "        \"\"\"\n",
    "        a = [X]\n",
    "        z = [X]\n",
    "        for l in range(len(self.layers)-1):\n",
    "            zl = np.dot(weights[l].transpose(), z[l])\n",
    "            if l == (len(self.layers)-2):\n",
    "                output = np.vectorize(math.exp)(zl)\n",
    "                output = output / output.sum()\n",
    "                a.append(output)\n",
    "                z.append(zl)\n",
    "            else:\n",
    "                z.append(np.insert(zl,0,1))\n",
    "                a.append(np.insert(self.activation_fn(zl),0,1))\n",
    "        return a,z\n",
    "    \n",
    "    def cross_entropy(self, weights):\n",
    "        entropy = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            a,z = self.get_network_output(np.insert(self.inputs[i], 0, 1), \n",
    "                                          weights)\n",
    "            y = a[-1]\n",
    "            t = self.outputs[i]\n",
    "            entropy += np.dot(t, np.vectorize(math.log)(y))\n",
    "        return -entropy\n",
    "    \n",
    "    def test(self, test_input, test_output, weights):\n",
    "        error = 0\n",
    "        for i in range(len(test_input)):\n",
    "            X = np.insert(test_input[i], 0, 1)\n",
    "            T = test_output[i]\n",
    "            a,z = self.get_network_output(X, weights)\n",
    "            predicted_digit = a[-1].argmax()\n",
    "            if T[predicted_digit] != 1:\n",
    "                error += 1\n",
    "        print \"Error is %.2f\" %(error*100/len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = MultiLayerNeuralNetwork(inputs=X[:20000],\n",
    "                                  outputs=Y[:20000],\n",
    "                                  learning_rate=0.001,\n",
    "                                  layers=[784,100,10],\n",
    "                                  activation_fn=sigmoid,\n",
    "                                  activation_derivative_fn=sigmoid_derivate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 83.50\n",
      "None\n",
      "Error is 68.10\n",
      "None\n",
      "Error is 54.20\n",
      "None\n",
      "Error is 45.20\n",
      "None\n",
      "Error is 40.20\n",
      "None\n",
      "Error is 37.90\n",
      "None\n",
      "Error is 35.40\n",
      "None\n",
      "Error is 33.10\n",
      "None\n",
      "Error is 31.30\n",
      "None\n",
      "Error is 29.80\n",
      "None\n",
      "Error is 27.80\n",
      "None\n",
      "Error is 26.10\n",
      "None\n",
      "Error is 25.30\n",
      "None\n",
      "Error is 24.90\n",
      "None\n",
      "Error is 23.40\n",
      "None\n",
      "Error is 23.00\n",
      "None\n",
      "Error is 22.40\n",
      "None\n",
      "Error is 21.50\n",
      "None\n",
      "Error is 21.00\n",
      "None\n",
      "Error is 20.50\n",
      "None\n",
      "Error is 20.10\n",
      "None\n",
      "Error is 19.70\n",
      "None\n",
      "Error is 19.30\n",
      "None\n",
      "Error is 19.00\n",
      "None\n",
      "Error is 19.00\n",
      "None\n",
      "Error is 18.10\n",
      "None\n",
      "Error is 17.30\n",
      "None\n",
      "Error is 16.80\n",
      "None\n",
      "Error is 16.40\n",
      "None\n",
      "Error is 16.40\n",
      "None\n",
      "Error is 16.00\n",
      "None\n",
      "Error is 15.60\n",
      "None\n",
      "Error is 15.10\n",
      "None\n",
      "Error is 14.80\n",
      "None\n",
      "Error is 14.60\n",
      "None\n",
      "Error is 14.40\n",
      "None\n",
      "Error is 13.90\n",
      "None\n",
      "Error is 13.80\n",
      "None\n",
      "Error is 13.50\n",
      "None\n",
      "Error is 13.40\n",
      "None\n",
      "Error is 13.30\n",
      "None\n",
      "Error is 12.90\n",
      "None\n",
      "Error is 12.60\n",
      "None\n",
      "Error is 12.20\n",
      "None\n",
      "Error is 12.20\n",
      "None\n",
      "Error is 12.00\n",
      "None\n",
      "Error is 11.90\n",
      "None\n",
      "Error is 11.70\n",
      "None\n",
      "Error is 11.60\n",
      "None\n",
      "Error is 11.50\n",
      "None\n",
      "Error is 11.20\n",
      "None\n",
      "Error is 10.70\n",
      "None\n",
      "Error is 10.60\n",
      "None\n",
      "Error is 10.70\n",
      "None\n",
      "Error is 10.70\n",
      "None\n",
      "Error is 10.70\n",
      "None\n",
      "Error is 10.20\n",
      "None\n",
      "Error is 10.30\n",
      "None\n",
      "Error is 10.20\n",
      "None\n",
      "Error is 10.10\n",
      "None\n",
      "Error is 10.00\n",
      "None\n",
      "Error is 10.00\n",
      "None\n",
      "Error is 9.70\n",
      "None\n",
      "Error is 9.70\n",
      "None\n",
      "Error is 9.40\n",
      "None\n",
      "Error is 9.20\n",
      "None\n",
      "Error is 9.10\n",
      "None\n",
      "Error is 8.70\n",
      "None\n",
      "Error is 8.50\n",
      "None\n",
      "Error is 8.40\n",
      "None\n",
      "Error is 8.20\n",
      "None\n",
      "Error is 7.80\n",
      "None\n",
      "Error is 7.60\n",
      "None\n",
      "Error is 7.60\n",
      "None\n",
      "Error is 7.40\n",
      "None\n",
      "Error is 7.30\n",
      "None\n",
      "Error is 7.10\n",
      "None\n",
      "Error is 6.90\n",
      "None\n",
      "Error is 6.70\n",
      "None\n",
      "Error is 6.40\n",
      "None\n",
      "Error is 6.30\n",
      "None\n",
      "Error is 6.10\n",
      "None\n",
      "Error is 6.00\n",
      "None\n",
      "Error is 5.90\n",
      "None\n",
      "Error is 5.90\n",
      "None\n",
      "Error is 5.90\n",
      "None\n",
      "Error is 5.60\n",
      "None\n",
      "Error is 5.30\n",
      "None\n",
      "Error is 5.30\n",
      "None\n",
      "Error is 5.00\n",
      "None\n",
      "Error is 4.90\n",
      "None\n",
      "Error is 4.50\n",
      "None\n",
      "Error is 4.30\n",
      "None\n",
      "Error is 4.10\n",
      "None\n",
      "Error is 4.00\n",
      "None\n",
      "Error is 3.90\n",
      "None\n",
      "Error is 3.80\n",
      "None\n",
      "Error is 3.80\n",
      "None\n",
      "Error is 3.70\n",
      "None\n",
      "Error is 3.70\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "weights = network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 32.00\n"
     ]
    }
   ],
   "source": [
    "network.test(X_test[:100], Y_test[:100], weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
