{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "from __future__          import division\n",
    "from scipy.stats         import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import array\n",
    "import math\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_mnist(images_file, labels_file): \n",
    "    f1 = open(labels_file, 'rb')\n",
    "    magic_number, size = struct.unpack(\">II\", f1.read(8))\n",
    "    labels = array.array(\"b\", f1.read())\n",
    "    f1.close()\n",
    "    \n",
    "    f2 = open(images_file, 'rb')\n",
    "    magic_number, size, rows, cols = struct.unpack(\">IIII\", f2.read(16))\n",
    "    raw_images = array.array(\"B\", f2.read())\n",
    "    f2.close()\n",
    "\n",
    "    N = len(labels)\n",
    "    images = np.zeros((N, rows*cols), dtype=np.uint8)\n",
    "    for i in range(N):\n",
    "        images[i] = np.array(raw_images[ i*rows*cols : (i+1)*rows*cols ])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Read Training data.\n",
    "TRAIN_IMAGES  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-images.idx3-ubyte\"\n",
    "TRAIN_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\train-labels.idx1-ubyte\"\n",
    "images_train, labels_train = read_mnist(TRAIN_IMAGES, TRAIN_LABELS)\n",
    "#images_train, labels_train = images_train[:20000], labels_train[:20000]\n",
    "\n",
    "# Read Test data.\n",
    "TEST_IMAGES = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-images.idx3-ubyte\"\n",
    "TEST_LABELS  = \"C:\\\\Users\\\\oop\\\\Desktop\\\\Winter 2016\\\\t10k-labels.idx1-ubyte\"\n",
    "images_test, labels_test = read_mnist(TEST_IMAGES, TEST_LABELS)\n",
    "#images_test, labels_test = images_test[:2000], labels_test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid(ele) for ele in x])\n",
    "    else:\n",
    "        return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    if type(x) is np.ndarray or type(x) is list:\n",
    "        return np.array([sigmoid_derivate(ele) for ele in x])\n",
    "    else:\n",
    "        a = sigmoid(x)\n",
    "        return a * (1-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = zscore(images_train, axis=1)\n",
    "Y = [[1 if i == label else 0 for i in range(10)] for label in labels_train]\n",
    "X_test = zscore(images_test, axis=1)\n",
    "Y_test = [[1 if i == label else 0 for i in range(10)] for label in labels_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiLayerNeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, outputs, learning_rate, hidden_layers, \n",
    "                 activation_fn, activation_derivative_fn, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        TODO: Add doc.\n",
    "        \"\"\"\n",
    "        self.inputs = inputs\n",
    "        self.outputs = outputs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.activation_fn = activation_fn\n",
    "        self.activation_derivative_fn = activation_derivative_fn\n",
    "    \n",
    "    def get_random_weights(self):\n",
    "        weights = []\n",
    "        # Input layer to first hidden layer.\n",
    "        weights.append(np.random.random((len(self.inputs[0])+1, self.hidden_layers[0])))\n",
    "        # Add weights between hidden layer.\n",
    "        for i in range(0, len(self.hidden_layers)-1):\n",
    "            weights.append(np.random.random((self.hidden_layers[i]+1, self.hidden_layers[i+1])))\n",
    "        # Add weights between last hidden layer and output layer.\n",
    "        weights.append(np.random.random((self.hidden_layers[-1]+1, len(self.outputs[0]))))\n",
    "        return weights\n",
    "    \n",
    "    def get_gradients(self, X, Y, weights):\n",
    "        # Forward propogation.\n",
    "        a,z = self.get_network_output(X, weights)\n",
    "        # Backward error propogation.\n",
    "        deltas = []\n",
    "        deltas.append((a[-1] - Y)) #*self.activation_derivative_fn(z[-1]))\n",
    "        for l in reversed(range(1, len(self.hidden_layers)+1)):\n",
    "            deltas.append(np.dot(weights[l], deltas[-1])*self.activation_derivative_fn(z[l]))\n",
    "        deltas.reverse()\n",
    "        \n",
    "        gradients = []\n",
    "        for i in range(len(weights)):\n",
    "            if i != (len(weights)-1):\n",
    "                deltas[i] = deltas[i][1:]\n",
    "            gradients.append(np.matmul(np.matrix(a[i]).transpose(), np.matrix(deltas[i])))\n",
    "        return gradients\n",
    "    \n",
    "    def test_gradient(self):\n",
    "        weights = self.get_random_weights()\n",
    "        \n",
    "        # One train loop.\n",
    "        gradients = []\n",
    "        for i in range(len(weights)):\n",
    "            gradients.append(np.zeros(weights[i].shape))\n",
    "            \n",
    "        for i in range(len(self.inputs)):\n",
    "            X = np.insert(self.inputs[i], 0, 1)\n",
    "            Y = self.outputs[i]\n",
    "            batch_gradients = self.get_gradients(X,Y,weights)\n",
    "            for i in range(len(gradients)):\n",
    "                gradients[i] += batch_gradients[i]\n",
    "        \n",
    "        epsilon = 2*10**-5\n",
    "        for l in range(len(self.hidden_layers)+1):\n",
    "            for i in range(len(weights[l])):\n",
    "                for j in range(len(weights[l][i])):\n",
    "                    w = weights[l][i][j]\n",
    "                    weights[l][i][j] = w + epsilon\n",
    "                    val1 = self.cross_entropy(weights)\n",
    "                    weights[l][i][j] = w - epsilon\n",
    "                    val2 = self.cross_entropy(weights)\n",
    "                    weights[l][i][j] = w\n",
    "                    print (val1 - val2) / (2*epsilon)\n",
    "                    print (gradients[l][i][j])\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the data using multilayered.\n",
    "        \"\"\"\n",
    "        \n",
    "        weights = self.get_random_weights()\n",
    "        print self.cross_entropy(weights)\n",
    "        \n",
    "        # 5 iterations.\n",
    "        for i in range(50):\n",
    "            gradients = []\n",
    "            for i in range(len(weights)):\n",
    "                gradients.append(np.zeros(weights[i].shape))\n",
    "\n",
    "            for i in range(len(self.inputs)):\n",
    "                X = np.insert(self.inputs[i], 0, 1)\n",
    "                Y = self.outputs[i]\n",
    "                batch_gradients = self.get_gradients(X,Y,weights)\n",
    "                for i in range(len(gradients)):\n",
    "                    if weights[i].shape != batch_gradients[i].shape:\n",
    "                        raise Exception(\"FUCK YIU\")\n",
    "                        \n",
    "                    weights[i] += batch_gradients[i]\n",
    "            \n",
    "            # Use gradient descent algorithm to update\n",
    "            # accordingly due to error derivates.\n",
    "            #for i in range(len(weights)):\n",
    "            #    weights[i] = weights[i] + self.learning_rate * gradients[i]\n",
    "\n",
    "        print self.cross_entropy(weights)\n",
    "        \n",
    "        self.weights = weights\n",
    "        return weights\n",
    "        \n",
    "    def get_network_output(self, X, weights):\n",
    "        \"\"\"\n",
    "        Calculates the output at each layer of the network.\n",
    "        \"\"\"\n",
    "        a = [X]\n",
    "        z = [X]\n",
    "        for l in range(len(self.hidden_layers)+1):\n",
    "            zl = np.dot(weights[l].transpose(), z[l])\n",
    "            if l == len(self.hidden_layers):\n",
    "                # Softmax output function.\n",
    "                output = np.vectorize(math.exp)(zl)\n",
    "                output = output / output.sum()\n",
    "                a.append(output)\n",
    "                z.append(zl)\n",
    "            else:\n",
    "                z.append(np.insert(zl,0,1))\n",
    "                al = self.activation_fn(zl)\n",
    "                # Add bias.\n",
    "                a.append(np.insert(al,0,1))\n",
    "        return a,z\n",
    "    \n",
    "    def cross_entropy(self, weights):\n",
    "        entropy = 0\n",
    "        for i in range(len(self.inputs)):\n",
    "            a,z = self.get_network_output(np.insert(self.inputs[i], 0, 1), weights)\n",
    "            y = a[-1]\n",
    "            t = self.outputs[i]\n",
    "            entropy = np.dot(t, np.vectorize(math.log)(y))\n",
    "        return -entropy\n",
    "    \n",
    "    def test(self, test_input, test_output):\n",
    "        weights = self.weights\n",
    "        error = 0\n",
    "        for i in range(len(test_input)):\n",
    "            X = np.insert(test_input[i], 0, 1)\n",
    "            T = test_output[i]\n",
    "            a,z = self.get_network_output(X, weights)\n",
    "            predicted_digit = a[-1].argmax()\n",
    "            if T[predicted_digit] != 1:\n",
    "                error += 1\n",
    "        print \"Error is %.2f\" %(error*100/len(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = MultiLayerNeuralNetwork(inputs=X[:2],\n",
    "                                  outputs=Y[:2],\n",
    "                                  learning_rate=0.0001,\n",
    "                                  hidden_layers=[2],\n",
    "                                  activation_fn=sigmoid,\n",
    "                                  activation_derivative_fn=sigmoid_derivate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.37609340408\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-60a8f91cf568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-7c620d1c70bc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mbatch_gradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbatch_gradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-7c620d1c70bc>\u001b[0m in \u001b[0;36mget_gradients\u001b[1;34m(self, X, Y, weights)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Forward propogation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_network_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Backward error propogation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mdeltas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-7c620d1c70bc>\u001b[0m in \u001b[0;36mget_network_output\u001b[1;34m(self, X, weights)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;31m# Softmax output function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1809\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1811\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.pyc\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   1878\u001b[0m                       for _a in args]\n\u001b[0;32m   1879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: math range error"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m(1880)\u001b[0;36m_vectorize_call\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   1879 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 1880 \u001b[1;33m            \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1881 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "weights = network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 88.30\n"
     ]
    }
   ],
   "source": [
    "network.test(X_test[:1000], Y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.get_network_output(X_test[:1][0], network.weights)[0][-1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25727236773054124"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*np.random.random((3,1))-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(aa, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MultiLayerNeuralNetwork instance at 0x0000000019F397C8>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
